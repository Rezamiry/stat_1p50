{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1OEgWxxky1BLQHmPWZ79o4zLB3yA69TBa",
      "authorship_tag": "ABX9TyN2pCurFS/KolClFtvpXqK9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rezamiry/stat_1p50/blob/main/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download keras model and dataset\n",
        "!gdown 1-CqVU9Lhc66XiNQ2qPctgy3LtdbCV2v4\n",
        "!gdown 1Zr1ydGNEAIFWNwCQ9cColpSAEme4ZMcd -O ./dataset --folder\n",
        "\n",
        "# download necessary packages\n",
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "id": "I9V0QQzR1l9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from facenet_pytorch import MTCNN\n",
        "from sklearn.preprocessing import Normalizer"
      ],
      "metadata": {
        "id": "G2SjBgb5k77_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')\n",
        "# output: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')] if not change the runtime to gpu"
      ],
      "metadata": {
        "id": "TBrlVB1YE59d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained model\n",
        "facenet = tf.keras.models.load_model(\"./facenet_keras.h5\")\n",
        "mtcnn = MTCNN(post_process=False, device=\"cuda:0\")\n",
        "normalizer = Normalizer(norm='l2')"
      ],
      "metadata": {
        "id": "3xHrPI2JCaRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_face(image_path, required_size=(160,160)):\n",
        "\n",
        "  \"\"\"\n",
        "    Implement face detection.\n",
        "    \n",
        "    Arguments:\n",
        "        image_path -- path to an image\n",
        "    \n",
        "    Returns:\n",
        "        face -- cropped face in image, None if there is not face in image'\n",
        "    \n",
        "    face_detector.detect\n",
        "      input: Image object\n",
        "      output: bounding boxes, probabilities\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  ### Your code starts here\n",
        "\n",
        "  # open image with Image.open and store in image variable\n",
        "  \n",
        "  # convert image to RGB\n",
        "  \n",
        "  # detect face in image and store bounding boxes in bbox\n",
        "  \n",
        "\n",
        "  #### Your code ends here\n",
        "  if bbox is None:\n",
        "    return None\n",
        "  bbox = bbox[0]\n",
        "  face = image.crop(bbox)\n",
        "  face = face.resize(required_size)\n",
        "  return np.array(face)[None,:]"
      ],
      "metadata": {
        "id": "IxHaaa2oENy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your code\n",
        "face_temp = get_face(\"./dataset/aldawsari.jpg\")\n",
        "assert (face_temp[0][0][0:2] == np.array([[11,10,7], [9,8,6]])).all()\n",
        "original_image = Image.open(\"./dataset/aldawsari.jpg\").resize((320,320))\n",
        "croped_image =  Image.fromarray(face_temp[0])\n",
        "display(original_image)\n",
        "display(croped_image)"
      ],
      "metadata": {
        "id": "QsLLfgsGHSQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(face):\n",
        "  \"\"\"\n",
        "    Implement embedding function.\n",
        "    \n",
        "    Arguments:\n",
        "        face -- numpy array, output of get_face function\n",
        "    \n",
        "    Returns:\n",
        "        embedding -- 128 embeding of input face\n",
        "    \n",
        "    facenet.predict\n",
        "      input: numpy array of face\n",
        "      output: embedding\n",
        "  \"\"\"\n",
        "  face_pixel = face.astype('float32')\n",
        "\n",
        "  ### Your code start here\n",
        "\n",
        "  # standardize pixel values across channels (global), subtract mean and divide by std\n",
        "  \n",
        "\n",
        "  # get the embedding using facenet.predict\n",
        "  \n",
        "\n",
        "  ### Your code ends here\n",
        "  normalized_embedding = normalizer.transform(embedding.reshape((1, -1)))\n",
        "  return normalized_embedding"
      ],
      "metadata": {
        "id": "FUmGOakk6YcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your code\n",
        "face_temp = get_face(\"./dataset/muller.jpg\")\n",
        "embed_temp = get_embedding(face_temp)\n",
        "assert np.allclose(embed_temp[0][:10], np.array([ 0.12399978,  0.06491313,  0.01508836, -0.07145731, -0.06072073,\n",
        "        0.10177094, -0.18736975, -0.07607765,  0.05578641, -0.15414089]))\n",
        "print(\"Your get_embedding function worked!\")\n"
      ],
      "metadata": {
        "id": "KN0G6mi5MYdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_distance(embed_1, embed_2):\n",
        "  \"\"\"\n",
        "    Implement calculate_distance function\n",
        "    \n",
        "    Arguments:\n",
        "        embed_1 -- embedding 1\n",
        "        embed_2 -- embedding 2\n",
        "    \n",
        "    Returns:\n",
        "        distance -- second norm of distane of inputs\n",
        "    \n",
        "  \"\"\"\n",
        "  ### Your code start here\n",
        "  \n",
        "  # calculate second norm of distance of inputs and store it in distance variable, use linalg.norm of numpy package\n",
        "  \n",
        "\n",
        "  ### Your code ends here\n",
        "  return distance"
      ],
      "metadata": {
        "id": "PNrNyc-j63RX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your code here\n",
        "f1 = get_face(\"./dataset/aldawsari.jpg\")\n",
        "f2 = get_face(\"./dataset/aldawsari_test.jpg\")\n",
        "em1 = get_embedding(f1)\n",
        "em2 = get_embedding(f2)\n",
        "dist = calculate_distance(em1, em2)\n",
        "assert np.isclose(dist, 0.67616165)\n",
        "print(\"Your code has worked!\")"
      ],
      "metadata": {
        "id": "-NLWQ8qXORY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dictionary with names and embeddings of all players - except test images and picture1, picture2\n",
        "dataset = {}\n",
        "### Your code starts here\n"
      ],
      "metadata": {
        "id": "Ma_VaiHyQW5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_verification(image_path, identity):\n",
        "  \"\"\"\n",
        "    Implement face verification.\n",
        "    \n",
        "    Arguments:\n",
        "        image_path -- path to image\n",
        "    \n",
        "    Returns:\n",
        "        verified -- True or False\n",
        "    \n",
        "  \"\"\"\n",
        "  ### Your code start here\n",
        "\n",
        "\n",
        "\n",
        "  ### Your code ends here\n",
        "  return verified"
      ],
      "metadata": {
        "id": "ahUgsxnPSCyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def face_recognition(image_path):\n",
        "  \"\"\"\n",
        "    Implement face verification.\n",
        "    \n",
        "    Arguments:\n",
        "        image_path -- path to image\n",
        "    \n",
        "    Returns:\n",
        "        identity -- name of recognizied person or \"unknown\"\n",
        "    \n",
        "  \"\"\"\n",
        "  ### Your code start here\n",
        "\n",
        "\n",
        "\n",
        "  ### Your code ends here\n",
        "  return identity"
      ],
      "metadata": {
        "id": "77f5CjVCSurg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}